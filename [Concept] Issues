
Q: https://github.com/kubernetes-client/java/issues/86
2021-02-03 09:30:23,830 | INFO  | async-executor-6     | c.h.h.t.service.platform.CceService | deleteJob() 160 | Catching exception because kubernetes delete bugs , cause : 
java.lang.IllegalStateException: Expected a string but was BEGIN_OBJECT at line 1 column 4218 path $.status
	at com.google.gson.stream.JsonReader.nextString(JsonReader.java:826)
	at com.google.gson.internal.bind.TypeAdapters$16.read(TypeAdapters.java:402)
	at com.google.gson.internal.bind.TypeAdapters$16.read(TypeAdapters.java:390)
	at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$1.read(ReflectiveTypeAdapterFactory.java:131)
	at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:222)
	at com.google.gson.Gson.fromJson(Gson.java:932)
	at com.google.gson.Gson.fromJson(Gson.java:897)
	at com.google.gson.Gson.fromJson(Gson.java:846)
	at io.kubernetes.client.openapi.JSON.deserialize(JSON.java:139)
	at io.kubernetes.client.openapi.ApiClient.deserialize(ApiClient.java:765)
	at io.kubernetes.client.openapi.ApiClient.handleResponse(ApiClient.java:968)
	at io.kubernetes.client.openapi.ApiClient.execute(ApiClient.java:895)
	at io.kubernetes.client.openapi.apis.BatchV1Api.deleteNamespacedJobWithHttpInfo(BatchV1Api.java:582)
	at com.huawei.hwoctopus.trainserver.service.platform.CceService.deleteJob(CceService.java:148)
	at com.huawei.hwoctopus.trainserver.service.platform.train.TrainCceService.deleteJob(TrainCceService.java:144)
	...
	
Fix:
https://github.com/kubernetes-client/java/pull/1445/commits/030261885269717a9888c43779b7d9db7180f262


Q:
root@ecs-train-kubernetes-hdfs-0001:~/apiserver# kubectl apply -f apiserver-deployment.yaml
secret/crypto unchanged
error: error parsing apiserver-deployment.yaml: error converting YAML to JSON: yaml: line 57: mapping values are not allowed in this context

Note: If you have multiple files separated by "---" in a same yaml file, the line number actually count from the start of the nearest '---', which may lead to confusion if you count from the start of the whole file.

Always use YAML Linter before submitting(http://www.yamllint.com/).

3. Q: Delete ingress-controller, ingress-nginx namespace stuck at Terminating
```
	service@c-project-host-001:/etc/kubernetes$ kubectl get ns
	NAME              STATUS        AGE
	default           Active        26d
	dev-agent         Active        11d
	ingress-nginx     Terminating   120m
	
	service@c-project-host-001:/etc/kubernetes$ kubectl get all -n ingress-nginx
	No resources found.
	
	service@c-project-host-001:/etc/kubernetes$ kubectl get ns ingress-nginx -o yaml
	apiVersion: v1
	kind: Namespace
	metadata:
	  annotations:
	    kubectl.kubernetes.io/last-applied-configuration: |
	      {"apiVersion":"v1","kind":"Namespace","metadata":{"annotations":{},"labels":{"app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"name":"ingress-nginx"}}
	  creationTimestamp: "2021-06-21T06:17:21Z"
	  deletionTimestamp: "2021-06-21T06:19:34Z"
	  labels:
	    app.kubernetes.io/instance: ingress-nginx
	    app.kubernetes.io/name: ingress-nginx
	  name: ingress-nginx
	  resourceVersion: "3906342"
	  selfLink: /api/v1/namespaces/ingress-nginx
	  uid: 8daa62ee-14b2-45bd-9318-a0656bd9b5f6
	spec:
	  finalizers:
	  - kubernetes
	status:
	  phase: Terminating
````
	
Most answers mention editing the yaml file or update the k8s object to clear the finalizer array, which will not solve the real problem.
````	
	service@c-project-host-001:/etc/kubernetes$ kubectl api-resources
	...
	clusterrolebindings                            rbac.authorization.k8s.io      false        ClusterRoleBinding
	clusterroles                                   rbac.authorization.k8s.io      false        ClusterRole
	rolebindings                                   rbac.authorization.k8s.io      true         RoleBinding
	roles                                          rbac.authorization.k8s.io      true         Role
	priorityclasses                   pc           scheduling.k8s.io              false        PriorityClass
	csidrivers                                     storage.k8s.io                 false        CSIDriver
	csinodes                                       storage.k8s.io                 false        CSINode
	storageclasses                    sc           storage.k8s.io                 false        StorageClass
	volumeattachments                              storage.k8s.io                 false        VolumeAttachment
	error: unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
	
	service@c-project-host-001:/etc/kubernetes$ kubectl get apiservices v1beta1.metrics.k8s.io -o yaml
	apiVersion: apiregistration.k8s.io/v1
	kind: APIService
	metadata:
	  annotations:
	    kubectl.kubernetes.io/last-applied-configuration: |
	      {"apiVersion":"apiregistration.k8s.io/v1beta1","kind":"APIService","metadata":{"annotations":{},"name":"v1beta1.metrics.k8s.io"},"spec":{"group":"metrics.k8s.io","groupPriorityMinimum":100,"insecureSkipTLSVerify":true,"service":{"name":"metrics-server","namespace":"kube-system"},"version":"v1beta1","versionPriority":100}}
	  creationTimestamp: "2021-05-28T02:46:54Z"
	  name: v1beta1.metrics.k8s.io
	  resourceVersion: "3749855"
	  selfLink: /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.metrics.k8s.io
	  uid: 9759758e-54f5-417e-9704-4e17b355be1e
	spec:
	  group: metrics.k8s.io
	  groupPriorityMinimum: 100
	  insecureSkipTLSVerify: true
	  service:
	    name: metrics-server
	    namespace: kube-system
	    port: 443
	  version: v1beta1
	  versionPriority: 100
	status:
	  conditions:
	  - lastTransitionTime: "2021-06-20T04:52:14Z"
	    message: endpoints for service/metrics-server in "kube-system" have no addresses
	      with port name ""
	    reason: MissingEndpoints
	    status: "False"
	    type: Available
````
Restart the metric server finally solved the problem.


Q: How to copy file to/from host machine
A:
To copy a file from the local file system to a container, run the command for Docker container or Kubernetes pod, respectively:
````
docker cp <src-path> <container>:<dest-path> 
kubectl cp <src-path> <your-pod-name>:<dest-path> 
````
For example:
````
docker cp "C:\ProcDump\procdump64.exe" sitecore-xm1_cm_1:"C:\" 
kubectl cp "C:\ProcDump\procdump64.exe" k8s-xm-cm-pod:procdump64.exe
````
To copy a file from the container to the local file system, use:
````
docker cp <container>:<src-path> <local-dest-path> 
kubectl cp <your-pod-name>:<src-path> <local-dest-path> 
````
For example:
````
docker cp sitecore-xm1_cm_1:"C:\inetpub\wwwroot\App_Data\logs" "C:\" 
kubectl cp k8s-xm-cm-pod:some-file.txt "C:\"
````

Q:  Failed to setup network for pod \ using network plugins \"cni\": no IP addresses available in network: podnet; Skipping pod
A: 
This started to happen after I did a kubeadm reset and kubeadm init/join ... again.
Here's what I did to fix (on master and slaves):
````
kubeadm reset
systemctl stop kubelet
systemctl stop docker

rm -rf /var/lib/cni/
rm -rf /var/lib/kubelet/*
rm -rf /etc/cni/

ifconfig cni0 down
ifconfig flannel.1 down
ifconfig docker0 down

ip link delete cni0
ip link delete flannel.1
````
(you may need to manually umount filesystems from /var/lib/kubelet before calling rm on that dir)
After doing that I started docker manually and restarted the kubeadm process

Q: Host is unreachable. The upstream ingress-nginx controller directs doesn't even exists!
ingress nginx log:
2021/08/12 [error] 2498#2498: *13169113 connect() failed (113: Host is unreachable) while connecting to upstream, client: 10.244.0.1, server: _, request: "GET /admin/inner-api/data/resource/usage

A:
Tried to delete and restart deployment, this issue persists.
Since I just changed the system time, think the reason might be the upstream of the service is cached in ingress-nginx controller in a time-based manner, maybe the time change cause it to lookup the old value not valid any more.

Restarting ingress-nginx controller solved this issue.+

Q: Ingress-NGINX returns 400 with follwing text/html message:
````
<html>
<head>
    <title>400 Request Header Or Cookie Too Large</title>
</head>
<body>
    <center>
        <h1>400 Bad Request</h1>
    </center>
    <center>Request Header Or Cookie Too Large</center>
    <hr>
    <center>nginx</center>
</body>
</html>
````
A: Knowing the reason being that the 'Authorization' header is too large ~8.2k bytesï¼Œ I changed the access endpoint from ingress-nginx controller to in-cluster service address(octopus-common-apiserver-user.default.svc.cluster.local:8902) to bypass nginx, but it seems the request still goes through ingress-nginx(w/ same return value and through NGINX log trace)! Finally the problem is solved though the following annotation:


<pre><code>
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/backend-protocol: HTTP
    nginx.ingress.kubernetes.io/client-body-buffer-size: 64k
    nginx.ingress.kubernetes.io/client-header-buffer-size: 100k
    nginx.ingress.kubernetes.io/http2-max-header-size: 96k
    nginx.ingress.kubernetes.io/large-client-header-buffers: 4 100k
    nginx.ingress.kubernetes.io/load-balance: ewma
    nginx.ingress.kubernetes.io/proxy-body-size: 150m
    nginx.ingress.kubernetes.io/proxy-buffer-size: 96k
    nginx.ingress.kubernetes.io/proxy-read-timeout: "1000"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "1000"
    <b>nginx.ingress.kubernetes.io/server-snippet: | # this is where the magic happens
      client_header_buffer_size 100k;
      large_client_header_buffers 4 100k;</b>
      ...
</code></pre>

Q: Sync pod time with host machine time?
A: 
````
$ ll /etc/local*
Irwxrwxrwx 1 root root 33 Nov 17 2021 /etc/localtime -> /usr/share/zoneinfo/asia/Shanghai
````
